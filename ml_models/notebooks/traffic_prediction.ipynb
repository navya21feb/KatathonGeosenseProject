{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Traffic Prediction Model\n",
        "\n",
        "This notebook contains the ML model for predicting traffic patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{\n",
        " \"cells\": [\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"# GeoSense Traffic Prediction Model\\n\",\n",
        "    \"## Exploratory Data Analysis and Model Training\\n\",\n",
        "    \"\\n\",\n",
        "    \"This notebook demonstrates:\\n\",\n",
        "    \"1. Data loading and exploration\\n\",\n",
        "    \"2. Feature engineering\\n\",\n",
        "    \"3. Model training and evaluation\\n\",\n",
        "    \"4. Predictions and visualizations\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Import libraries\\n\",\n",
        "    \"import pandas as pd\\n\",\n",
        "    \"import numpy as np\\n\",\n",
        "    \"import matplotlib.pyplot as plt\\n\",\n",
        "    \"import seaborn as sns\\n\",\n",
        "    \"from sklearn.model_selection import train_test_split\\n\",\n",
        "    \"from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\\n\",\n",
        "    \"from sklearn.preprocessing import StandardScaler\\n\",\n",
        "    \"from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\\n\",\n",
        "    \"import joblib\\n\",\n",
        "    \"from datetime import datetime\\n\",\n",
        "    \"import warnings\\n\",\n",
        "    \"warnings.filterwarnings('ignore')\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Set style\\n\",\n",
        "    \"sns.set_style('whitegrid')\\n\",\n",
        "    \"plt.rcParams['figure.figsize'] = (12, 6)\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(\\\"Libraries imported successfully!\\\")\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 1. Data Loading\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Load processed data\\n\",\n",
        "    \"data_path = '../data/processed/traffic_data_processed.csv'\\n\",\n",
        "    \"\\n\",\n",
        "    \"try:\\n\",\n",
        "    \"    df = pd.read_csv(data_path)\\n\",\n",
        "    \"    print(f\\\"Data loaded successfully: {len(df)} records\\\")\\n\",\n",
        "    \"except FileNotFoundError:\\n\",\n",
        "    \"    print(\\\"Processed data not found. Generating synthetic data...\\\")\\n\",\n",
        "    \"    # Generate synthetic data\\n\",\n",
        "    \"    np.random.seed(42)\\n\",\n",
        "    \"    n_samples = 10000\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    data = []\\n\",\n",
        "    \"    for _ in range(n_samples):\\n\",\n",
        "    \"        hour = np.random.randint(0, 24)\\n\",\n",
        "    \"        day_of_week = np.random.randint(0, 7)\\n\",\n",
        "    \"        lat = np.random.uniform(28.4, 28.7)\\n\",\n",
        "    \"        lon = np.random.uniform(77.0, 77.4)\\n\",\n",
        "    \"        is_weekend = 1 if day_of_week >= 5 else 0\\n\",\n",
        "    \"        is_peak_hour = 1 if (7 <= hour <= 9 or 17 <= hour <= 19) and not is_weekend else 0\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        base_congestion = 0.3\\n\",\n",
        "    \"        if is_peak_hour:\\n\",\n",
        "    \"            base_congestion += 0.4\\n\",\n",
        "    \"        if not is_weekend:\\n\",\n",
        "    \"            base_congestion += 0.2\\n\",\n",
        "    \"        if 22 <= hour or hour <= 5:\\n\",\n",
        "    \"            base_congestion -= 0.2\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        congestion_level = np.clip(base_congestion + np.random.normal(0, 0.1), 0, 1)\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        data.append({\\n\",\n",
        "    \"            'hour': hour,\\n\",\n",
        "    \"            'day_of_week': day_of_week,\\n\",\n",
        "    \"            'lat': lat,\\n\",\n",
        "    \"            'lon': lon,\\n\",\n",
        "    \"            'is_weekend': is_weekend,\\n\",\n",
        "    \"            'is_peak_hour': is_peak_hour,\\n\",\n",
        "    \"            'congestion_level': congestion_level\\n\",\n",
        "    \"        })\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    df = pd.DataFrame(data)\\n\",\n",
        "    \"    print(f\\\"Synthetic data generated: {len(df)} records\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Display first few rows\\n\",\n",
        "    \"df.head()\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 2. Exploratory Data Analysis\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Basic statistics\\n\",\n",
        "    \"print(\\\"Dataset Shape:\\\", df.shape)\\n\",\n",
        "    \"print(\\\"\\\\nColumn Types:\\\")\\n\",\n",
        "    \"print(df.dtypes)\\n\",\n",
        "    \"print(\\\"\\\\nMissing Values:\\\")\\n\",\n",
        "    \"print(df.isnull().sum())\\n\",\n",
        "    \"print(\\\"\\\\nBasic Statistics:\\\")\\n\",\n",
        "    \"df.describe()\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Congestion level distribution\\n\",\n",
        "    \"plt.figure(figsize=(12, 4))\\n\",\n",
        "    \"\\n\",\n",
        "    \"plt.subplot(1, 3, 1)\\n\",\n",
        "    \"plt.hist(df['congestion_level'], bins=30, edgecolor='black', alpha=0.7)\\n\",\n",
        "    \"plt.xlabel('Congestion Level')\\n\",\n",
        "    \"plt.ylabel('Frequency')\\n\",\n",
        "    \"plt.title('Distribution of Congestion Levels')\\n\",\n",
        "    \"\\n\",\n",
        "    \"plt.subplot(1, 3, 2)\\n\",\n",
        "    \"hourly_congestion = df.groupby('hour')['congestion_level'].mean()\\n\",\n",
        "    \"plt.plot(hourly_congestion.index, hourly_congestion.values, marker='o')\\n\",\n",
        "    \"plt.xlabel('Hour of Day')\\n\",\n",
        "    \"plt.ylabel('Average Congestion')\\n\",\n",
        "    \"plt.title('Average Congestion by Hour')\\n\",\n",
        "    \"plt.grid(True, alpha=0.3)\\n\",\n",
        "    \"\\n\",\n",
        "    \"plt.subplot(1, 3, 3)\\n\",\n",
        "    \"day_congestion = df.groupby('day_of_week')['congestion_level'].mean()\\n\",\n",
        "    \"days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\\n\",\n",
        "    \"plt.bar(range(7), day_congestion.values, alpha=0.7)\\n\",\n",
        "    \"plt.xticks(range(7), days)\\n\",\n",
        "    \"plt.xlabel('Day of Week')\\n\",\n",
        "    \"plt.ylabel('Average Congestion')\\n\",\n",
        "    \"plt.title('Average Congestion by Day')\\n\",\n",
        "    \"\\n\",\n",
        "    \"plt.tight_layout()\\n\",\n",
        "    \"plt.show()\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Correlation heatmap\\n\",\n",
        "    \"plt.figure(figsize=(10, 8))\\n\",\n",
        "    \"correlation = df[['hour', 'day_of_week', 'lat', 'lon', 'is_weekend', 'is_peak_hour', 'congestion_level']].corr()\\n\",\n",
        "    \"sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0, fmt='.2f')\\n\",\n",
        "    \"plt.title('Feature Correlation Matrix')\\n\",\n",
        "    \"plt.tight_layout()\\n\",\n",
        "    \"plt.show()\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Peak hour vs non-peak hour comparison\\n\",\n",
        "    \"plt.figure(figsize=(10, 5))\\n\",\n",
        "    \"\\n\",\n",
        "    \"peak_data = df[df['is_peak_hour'] == 1]['congestion_level']\\n\",\n",
        "    \"non_peak_data = df[df['is_peak_hour'] == 0]['congestion_level']\\n\",\n",
        "    \"\\n\",\n",
        "    \"plt.subplot(1, 2, 1)\\n\",\n",
        "    \"plt.hist([peak_data, non_peak_data], bins=20, label=['Peak Hours', 'Non-Peak Hours'], alpha=0.7)\\n\",\n",
        "    \"plt.xlabel('Congestion Level')\\n\",\n",
        "    \"plt.ylabel('Frequency')\\n\",\n",
        "    \"plt.title('Congestion: Peak vs Non-Peak Hours')\\n\",\n",
        "    \"plt.legend()\\n\",\n",
        "    \"\\n\",\n",
        "    \"plt.subplot(1, 2, 2)\\n\",\n",
        "    \"plt.boxplot([peak_data, non_peak_data], labels=['Peak', 'Non-Peak'])\\n\",\n",
        "    \"plt.ylabel('Congestion Level')\\n\",\n",
        "    \"plt.title('Congestion Distribution')\\n\",\n",
        "    \"\\n\",\n",
        "    \"plt.tight_layout()\\n\",\n",
        "    \"plt.show()\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(f\\\"Peak Hours Average Congestion: {peak_data.mean():.3f}\\\")\\n\",\n",
        "    \"print(f\\\"Non-Peak Hours Average Congestion: {non_peak_data.mean():.3f}\\\")\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 3. Feature Engineering\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Define features and target\\n\",\n",
        "    \"feature_columns = ['hour', 'day_of_week', 'lat', 'lon', 'is_weekend', 'is_peak_hour']\\n\",\n",
        "    \"target_column = 'congestion_level'\\n\",\n",
        "    \"\\n\",\n",
        "    \"X = df[feature_columns]\\n\",\n",
        "    \"y = df[target_column]\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(f\\\"Features shape: {X.shape}\\\")\\n\",\n",
        "    \"print(f\\\"Target shape: {y.shape}\\\")\\n\",\n",
        "    \"print(f\\\"\\\\nFeatures: {feature_columns}\\\")\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 4. Model Training\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Split data\\n\",\n",
        "    \"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(f\\\"Training set: {len(X_train)} samples\\\")\\n\",\n",
        "    \"print(f\\\"Test set: {len(X_test)} samples\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Scale features\\n\",\n",
        "    \"scaler = StandardScaler()\\n\",\n",
        "    \"X_train_scaled = scaler.fit_transform(X_train)\\n\",\n",
        "    \"X_test_scaled = scaler.transform(X_test)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Train Random Forest\\n\",\n",
        "    \"print(\\\"Training Random Forest model...\\\")\\n\",\n",
        "    \"rf_model = RandomForestRegressor(\\n\",\n",
        "    \"    n_estimators=100,\\n\",\n",
        "    \"    max_depth=10,\\n\",\n",
        "    \"    random_state=42,\\n\",\n",
        "    \"    n_jobs=-1\\n\",\n",
        "    \")\\n\",\n",
        "    \"\\n\",\n",
        "    \"rf_model.fit(X_train_scaled, y_train)\\n\",\n",
        "    \"print(\\\"Training completed!\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Predictions\\n\",\n",
        "    \"y_train_pred_rf = rf_model.predict(X_train_scaled)\\n\",\n",
        "    \"y_test_pred_rf = rf_model.predict(X_test_scaled)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Train Gradient Boosting\\n\",\n",
        "    \"print(\\\"Training Gradient Boosting model...\\\")\\n\",\n",
        "    \"gb_model = GradientBoostingRegressor(\\n\",\n",
        "    \"    n_estimators=100,\\n\",\n",
        "    \"    max_depth=5,\\n\",\n",
        "    \"    learning_rate=0.1,\\n\",\n",
        "    \"    random_state=42\\n\",\n",
        "    \")\\n\",\n",
        "    \"\\n\",\n",
        "    \"gb_model.fit(X_train_scaled, y_train)\\n\",\n",
        "    \"print(\\\"Training completed!\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Predictions\\n\",\n",
        "    \"y_train_pred_gb = gb_model.predict(X_train_scaled)\\n\",\n",
        "    \"y_test_pred_gb = gb_model.predict(X_test_scaled)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 5. Model Evaluation\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Calculate metrics\\n\",\n",
        "    \"def evaluate_model(y_true, y_pred, model_name):\\n\",\n",
        "    \"    mse = mean_squared_error(y_true, y_pred)\\n\",\n",
        "    \"    rmse = np.sqrt(mse)\\n\",\n",
        "    \"    mae = mean_absolute_error(y_true, y_pred)\\n\",\n",
        "    \"    r2 = r2_score(y_true, y_pred)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    print(f\\\"\\\\n{model_name} Performance:\\\")\\n\",\n",
        "    \"    print(f\\\"  MSE:  {mse:.4f}\\\")\\n\",\n",
        "    \"    print(f\\\"  RMSE: {rmse:.4f}\\\")\\n\",\n",
        "    \"    print(f\\\"  MAE:  {mae:.4f}\\\")\\n\",\n",
        "    \"    print(f\\\"  R²:   {r2:.4f}\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    return {'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2}\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Evaluate both models\\n\",\n",
        "    \"print(\\\"=\\\" * 60)\\n\",\n",
        "    \"print(\\\"MODEL PERFORMANCE COMPARISON\\\")\\n\",\n",
        "    \"print(\\\"=\\\" * 60)\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(\\\"\\\\n--- RANDOM FOREST ---\\\")\\n\",\n",
        "    \"rf_train_metrics = evaluate_model(y_train, y_train_pred_rf, \\\"Random Forest (Train)\\\")\\n\",\n",
        "    \"rf_test_metrics = evaluate_model(y_test, y_test_pred_rf, \\\"Random Forest (Test)\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(\\\"\\\\n--- GRADIENT BOOSTING ---\\\")\\n\",\n",
        "    \"gb_train_metrics = evaluate_model(y_train, y_train_pred_gb, \\\"Gradient Boosting (Train)\\\")\\n\",\n",
        "    \"gb_test_metrics = evaluate_model(y_test, y_test_pred_gb, \\\"Gradient Boosting (Test)\\\")\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Visualize predictions vs actual\\n\",\n",
        "    \"fig, axes = plt.subplots(2, 2, figsize=(14, 10))\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Random Forest - Train\\n\",\n",
        "    \"axes[0, 0].scatter(y_train, y_train_pred_rf, alpha=0.5, s=10)\\n\",\n",
        "    \"axes[0, 0].plot([0, 1], [0, 1], 'r--', lw=2)\\n\",\n",
        "    \"axes[0, 0].set_xlabel('Actual Congestion')\\n\",\n",
        "    \"axes[0, 0].set_ylabel('Predicted Congestion')\\n\",\n",
        "    \"axes[0, 0].set_title(f'Random Forest - Training (R² = {rf_train_metrics[\\\"r2\\\"]:.3f})')\\n\",\n",
        "    \"axes[0, 0].grid(True, alpha=0.3)\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Random Forest - Test\\n\",\n",
        "    \"axes[0, 1].scatter(y_test, y_test_pred_rf, alpha=0.5, s=10)\\n\",\n",
        "    \"axes[0, 1].plot([0, 1], [0, 1], 'r--', lw=2)\\n\",\n",
        "    \"axes[0, 1].set_xlabel('Actual Congestion')\\n\",\n",
        "    \"axes[0, 1].set_ylabel('Predicted Congestion')\\n\",\n",
        "    \"axes[0, 1].set_title(f'Random Forest - Test (R² = {rf_test_metrics[\\\"r2\\\"]:.3f})')\\n\",\n",
        "    \"axes[0, 1].grid(True, alpha=0.3)\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Gradient Boosting - Train\\n\",\n",
        "    \"axes[1, 0].scatter(y_train, y_train_pred_gb, alpha=0.5, s=10)\\n\",\n",
        "    \"axes[1, 0].plot([0, 1], [0, 1], 'r--', lw=2)\\n\",\n",
        "    \"axes[1, 0].set_xlabel('Actual Congestion')\\n\",\n",
        "    \"axes[1, 0].set_ylabel('Predicted Congestion')\\n\",\n",
        "    \"axes[1, 0].set_title(f'Gradient Boosting - Training (R² = {gb_train_metrics[\\\"r2\\\"]:.3f})')\\n\",\n",
        "    \"axes[1, 0].grid(True, alpha=0.3)\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Gradient Boosting - Test\\n\",\n",
        "    \"axes[1, 1].scatter(y_test, y_test_pred_gb, alpha=0.5, s=10)\\n\",\n",
        "    \"axes[1, 1].plot([0, 1], [0, 1], 'r--', lw=2)\\n\",\n",
        "    \"axes[1, 1].set_xlabel('Actual Congestion')\\n\",\n",
        "    \"axes[1, 1].set_ylabel('Predicted Congestion')\\n\",\n",
        "    \"axes[1, 1].set_title(f'Gradient Boosting - Test (R² = {gb_test_metrics[\\\"r2\\\"]:.3f})')\\n\",\n",
        "    \"axes[1, 1].grid(True, alpha=0.3)\\n\",\n",
        "    \"\\n\",\n",
        "    \"plt.tight_layout()\\n\",\n",
        "    \"plt.show()\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Feature importance\\n\",\n",
        "    \"plt.figure(figsize=(10, 6))\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Random Forest feature importance\\n\",\n",
        "    \"rf_importance = pd.DataFrame({\\n\",\n",
        "    \"    'feature': feature_columns,\\n\",\n",
        "    \"    'importance': rf_model.feature_importances_\\n\",\n",
        "    \"}).sort_values('importance', ascending=True)\\n\",\n",
        "    \"\\n\",\n",
        "    \"plt.barh(rf_importance['feature'], rf_importance['importance'], alpha=0.8)\\n\",\n",
        "    \"plt.xlabel('Feature Importance')\\n\",\n",
        "    \"plt.title('Random Forest Feature Importance')\\n\",\n",
        "    \"plt.tight_layout()\\n\",\n",
        "    \"plt.show()\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(\\\"\\\\nFeature Importance Ranking:\\\")\\n\",\n",
        "    \"print(rf_importance.sort_values('importance', ascending=False).to_string(index=False))\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 6. Model Predictions\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Test predictions for different scenarios\\n\",\n",
        "    \"test_scenarios = [\\n\",\n",
        "    \"    {'hour': 8, 'day_of_week': 1, 'lat': 28.6139, 'lon': 77.2090, 'is_weekend': 0, 'is_peak_hour': 1, 'name': 'Monday 8 AM (Peak)'},\\n\",\n",
        "    \"    {'hour': 14, 'day_of_week': 1, 'lat': 28.6139, 'lon': 77.2090, 'is_weekend': 0, 'is_peak_hour': 0, 'name': 'Monday 2 PM'},\\n\",\n",
        "    \"    {'hour': 23, 'day_of_week': 1, 'lat': 28.6139, 'lon': 77.2090, 'is_weekend': 0, 'is_peak_hour': 0, 'name': 'Monday 11 PM'},\\n\",\n",
        "    \"    {'hour': 10, 'day_of_week': 6, 'lat': 28.6139, 'lon': 77.2090, 'is_weekend': 1, 'is_peak_hour': 0, 'name': 'Sunday 10 AM'},\\n\",\n",
        "    \"    {'hour': 18, 'day_of_week': 3, 'lat': 28.6139, 'lon': 77.2090, 'is_weekend': 0, 'is_peak_hour': 1, 'name': 'Thursday 6 PM (Peak)'}\\n\",\n",
        "    \"]\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(\\\"\\\\n\\\" + \\\"=\\\" * 80)\\n\",\n",
        "    \"print(\\\"SAMPLE PREDICTIONS\\\")\\n\",\n",
        "    \"print(\\\"=\\\" * 80)\\n\",\n",
        "    \"\\n\",\n",
        "    \"predictions_data = []\\n\",\n",
        "    \"\\n\",\n",
        "    \"for scenario in test_scenarios:\\n\",\n",
        "    \"    features = np.array([[scenario['hour'], scenario['day_of_week'], scenario['lat'], \\n\",\n",
        "    \"                         scenario['lon'], scenario['is_weekend'], scenario['is_peak_hour']]])\\n\",\n",
        "    \"    features_scaled = scaler.transform(features)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    rf_pred = rf_model.predict(features_scaled)[0]\\n\",\n",
        "    \"    gb_pred = gb_model.predict(features_scaled)[0]\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    # Classify congestion level\\n\",\n",
        "    \"    def classify_congestion(value):\\n\",\n",
        "    \"        if value < 0.3:\\n\",\n",
        "    \"            return 'Low'\\n\",\n",
        "    \"        elif value < 0.6:\\n\",\n",
        "    \"            return 'Moderate'\\n\",\n",
        "    \"        elif value < 0.8:\\n\",\n",
        "    \"            return 'High'\\n\",\n",
        "    \"        else:\\n\",\n",
        "    \"            return 'Severe'\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    print(f\\\"\\\\n{scenario['name']}:\\\")\\n\",\n",
        "    \"    print(f\\\"  Random Forest: {rf_pred:.3f} ({classify_congestion(rf_pred)})\\\")\\n\",\n",
        "    \"    print(f\\\"  Gradient Boost: {gb_pred:.3f} ({classify_congestion(gb_pred)})\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    predictions_data.append({\\n\",\n",
        "    \"        'Scenario': scenario['name'],\\n\",\n",
        "    \"        'RF_Prediction': rf_pred,\\n\",\n",
        "    \"        'GB_Prediction': gb_pred\\n\",\n",
        "    \"    })\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Visualize predictions\\n\",\n",
        "    \"pred_df = pd.DataFrame(predictions_data)\\n\",\n",
        "    \"pred_df.set_index('Scenario', inplace=True)\\n\",\n",
        "    \"\\n\",\n",
        "    \"pred_df.plot(kind='bar', figsize=(12, 6), alpha=0.8)\\n\",\n",
        "    \"plt.ylabel('Predicted Congestion Level')\\n\",\n",
        "    \"plt.title('Model Predictions for Different Scenarios')\\n\",\n",
        "    \"plt.xticks(rotation=45, ha='right')\\n\",\n",
        "    \"plt.legend(title='Model')\\n\",\n",
        "    \"plt.grid(axis='y', alpha=0.3)\\n\",\n",
        "    \"plt.tight_layout()\\n\",\n",
        "    \"plt.show()\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 7. Save Models\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Save models\\n\",\n",
        "    \"import os\\n\",\n",
        "    \"\\n\",\n",
        "    \"models_dir = '../saved_models'\\n\",\n",
        "    \"os.makedirs(models_dir, exist_ok=True)\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Save Random Forest (primary model)\\n\",\n",
        "    \"rf_path = os.path.join(models_dir, 'traffic_model.pkl')\\n\",\n",
        "    \"joblib.dump(rf_model, rf_path)\\n\",\n",
        "    \"print(f\\\"Random Forest model saved to: {rf_path}\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Save Gradient Boosting\\n\",\n",
        "    \"gb_path = os.path.join(models_dir, 'traffic_model_gb.pkl')\\n\",\n",
        "    \"joblib.dump(gb_model, gb_path)\\n\",\n",
        "    \"print(f\\\"Gradient Boosting model saved to: {gb_path}\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Save scaler\\n\",\n",
        "    \"scaler_path = os.path.join(models_dir, 'scaler.pkl')\\n\",\n",
        "    \"joblib.dump(scaler, scaler_path)\\n\",\n",
        "    \"print(f\\\"Scaler saved to: {scaler_path}\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(\\\"\\\\n✅ All models saved successfully!\\\")\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 8. Model Summary\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Summary\\n\",\n",
        "    \"summary = f\\\"\\\"\\\"\\n\",\n",
        "    \"{'='*80}\\n\",\n",
        "    \"                          MODEL TRAINING SUMMARY\\n\",\n",
        "    \"{'='*80}\\n\",\n",
        "    \"\\n\",\n",
        "    \"Dataset:\\n\",\n",
        "    \"  Total Samples: {len(df):,}\\n\",\n",
        "    \"  Training Set: {len(X_train):,} samples\\n\",\n",
        "    \"  Test Set: {len(X_test):,} samples\\n\",\n",
        "    \"\\n\",\n",
        "    \"Features:\\n\",\n",
        "    \"  {', '.join(feature_columns)}\\n\",\n",
        "    \"\\n\",\n",
        "    \"Random Forest Performance:\\n\",\n",
        "    \"  Test R²: {rf_test_metrics['r2']:.4f}\\n\",\n",
        "    \"  Test RMSE: {rf_test_metrics['rmse']:.4f}\\n\",\n",
        "    \"  Test MAE: {rf_test_metrics['mae']:.4f}\\n\",\n",
        "    \"\\n\",\n",
        "    \"Gradient Boosting Performance:\\n\",\n",
        "    \"  Test R²: {gb_test_metrics['r2']:.4f}\\n\",\n",
        "    \"  Test RMSE: {gb_test_metrics['rmse']:.4f}\\n\",\n",
        "    \"  Test MAE: {gb_test_metrics['mae']:.4f}\\n\",\n",
        "    \"\\n\",\n",
        "    \"Best Model: {'Random Forest' if rf_test_metrics['r2'] > gb_test_metrics['r2'] else 'Gradient Boosting'}\\n\",\n",
        "    \"\\n\",\n",
        "    \"Model Files Saved:\\n\",\n",
        "    \"  - traffic_model.pkl (Random Forest)\\n\",\n",
        "    \"  - traffic_model_gb.pkl (Gradient Boosting)\\n\",\n",
        "    \"  - scaler.pkl (Feature Scaler)\\n\",\n",
        "    \"\\n\",\n",
        "    \"{'='*80}\\n\",\n",
        "    \"\\\"\\\"\\\"\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(summary)\"\n",
        "   ]\n",
        "  }\n",
        " ],\n",
        " \"metadata\": {\n",
        "  \"kernelspec\": {\n",
        "   \"display_name\": \"Python 3\",\n",
        "   \"language\": \"python\",\n",
        "   \"name\": \"python3\"\n",
        "  },\n",
        "  \"language_info\": {\n",
        "   \"codemirror_mode\": {\n",
        "    \"name\": \"ipython\",\n",
        "    \"version\": 3\n",
        "   },\n",
        "   \"file_extension\": \".py\",\n",
        "   \"mimetype\": \"text/x-python\",\n",
        "   \"name\": \"python\",\n",
        "   \"nbconvert_exporter\": \"python\",\n",
        "   \"pygments_lexer\": \"ipython3\",\n",
        "   \"version\": \"3.8.0\"\n",
        "  }\n",
        " },\n",
        " \"nbformat\": 4,\n",
        " \"nbformat_minor\": 4\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
